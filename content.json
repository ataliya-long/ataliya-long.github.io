{"meta":{"title":"小塔的个人博客","subtitle":"","description":"","author":"Ataliya","url":"http://example.com","root":"/"},"pages":[{"title":"暂无","date":"2024-01-11T11:53:26.000Z","updated":"2024-01-11T12:42:37.938Z","comments":true,"path":"404/index.html","permalink":"http://example.com/404/index.html","excerpt":"","text":""},{"title":"关于作者","date":"2024-01-11T12:43:54.000Z","updated":"2024-01-11T12:55:29.168Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"我，Ataliya，自言自语六级，心里话八级，花式单身大赛赛区冠军，互联网冲浪资深选手，赖床锦标赛冠军得主，亚洲酸柠檬推广大使，熬夜杯曾十五次夺冠，这么厉害的我，不打算喜欢一下吗？"},{"title":"search","date":"2024-01-11T11:53:13.000Z","updated":"2024-01-11T11:53:13.158Z","comments":true,"path":"search/index.html","permalink":"http://example.com/search/index.html","excerpt":"","text":""}],"posts":[{"title":"安装TIDB单机版","slug":"安装TIDB单机版","date":"2024-01-13T11:49:48.000Z","updated":"2024-01-13T11:50:04.798Z","comments":true,"path":"2024/01/13/安装TIDB单机版/","permalink":"http://example.com/2024/01/13/%E5%AE%89%E8%A3%85TIDB%E5%8D%95%E6%9C%BA%E7%89%88/","excerpt":"","text":"安装TIDB单机版 要在 CentOS 上安装 TiDB 数据库的单机版，您可以按照以下步骤操作。在本示例中，我们将使用 TiUP 部署工具来部署 TiDB。 首先，确保您的 CentOS 系统已更新： 1sudo yum update 安装 TiUP： 1curl --proto &#x27;=https&#x27; --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh 将 TiUP 的二进制文件目录添加到 PATH 环境变量中： 12bashCopy codeecho &#x27;export PATH=$HOME/.tiup/bin:$PATH&#x27; &gt;&gt; ~/.bashrcsource ~/.bashrc 安装 TiUP 集群组件： 1tiup install cluster 部署单机版 TiDB： 我们将使用 TiUP 快速搭建一个单机版的 TiDB。运行以下命令： 1tiup playground 此命令将启动一个包括 1 个 PD（Placement Driver）、1 个 TiKV（分布式事务性键值存储）和 1 个 TiDB（分布式关系型数据库）组件的本地 TiDB 集群。 连接到 TiDB： 启动 tiup playground 后，您将看到一条消息，指示如何连接到 TiDB。默认情况下，TiDB 将监听在 127.0.0.1:4000 上。您可以使用 MySQL 客户端或兼容的工具连接到 TiDB。 例如，您可以使用 MySQL 命令行客户端连接到 TiDB。首先，确保已安装 MySQL 命令行客户端： 1sudo yum install -y mysql 然后，使用以下命令连接到 TiDB： 1mysql -h 127.0.0.1 -P 4000 -u root 现在，您已经成功在 CentOS 上安装并连接到了 TiDB 数据库的单机版。 将TIDB部署到生产环境当中 要将 TiDB 部署到生产环境，您需要采用更加稳定、安全的方式进行部署。TiUP 是官方推荐的部署工具。在以下示例中，我们将使用 TiUP 部署 TiDB 集群到生产环境。 准备环境： 确保您的 CentOS 系统已更新： 1sudo yum update 安装 TiUP： 1curl --proto &#x27;=https&#x27; --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh 将 TiUP 的二进制文件目录添加到 PATH 环境变量中： 12bashCopy codeecho &#x27;export PATH=$HOME/.tiup/bin:$PATH&#x27; &gt;&gt; ~/.bashrcsource ~/.bashrc 安装 TiUP 集群组件： 1tiup install cluster 准备部署配置文件： 在您的工作目录中创建一个名为 tidb_topology.yaml 的文件，并使用以下示例配置填充该文件： 123456789101112131415161718192021 user: &quot;tidb&quot; ssh_port: 22 deploy_dir: &quot;/tidb-deploy&quot; data_dir: &quot;/tidb-data&quot;pd_servers:- host: 10.0.1.1 - host: 10.0.1.2 - host: 10.0.1.3tikv_servers: - host: 10.0.1.4 - host: 10.0.1.5 - host: 10.0.1.6tidb_servers: - host: 10.0.1.7 - host: 10.0.1.8tiflash_servers: - host: 10.0.1.9 请注意，您需要将上述配置文件中的 IP 地址替换为您实际服务器的 IP 地址。 使用 TiUP 部署集群： 1tiup cluster deploy &lt;cluster-name&gt; &lt;tidb-version&gt; /path/to/tidb_topology.yaml --user root 将 &lt;cluster-name&gt; 替换为您的集群名称，&lt;tidb-version&gt; 替换为您想要部署的 TiDB 版本，例如 “v5.1.1”，并将 /path/to/tidb_topology.yaml 替换为您实际的配置文件路径。 部署成功后，TiUP 会显示集群的部署信息和访问方式。 启动集群： 1tiup cluster start &lt;cluster-name&gt; 将 &lt;cluster-name&gt; 替换为您的集群名称。 检查集群状态： 1tiup cluster display &lt;cluster-name&gt; 将 &lt;cluster-name&gt; 替换为您的集群名称。 现在，您已经成功部署了一个生产环境的 TiDB 集群。要管理和维护集群，请参阅 TiDB 官方文档，了解更多关于 TiUP 和其他管理工具的详细信息。","categories":[],"tags":[]},{"title":"PostgreSQL安装","slug":"PostgreSQL安装","date":"2024-01-13T11:49:13.000Z","updated":"2024-01-13T11:49:24.734Z","comments":true,"path":"2024/01/13/PostgreSQL安装/","permalink":"http://example.com/2024/01/13/PostgreSQL%E5%AE%89%E8%A3%85/","excerpt":"","text":"添加 PostgreSQL Yum Repository：PostgreSQL 官方提供了 Yum Repository，你可以通过以下命令添加此 Repository： 1sudo yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm 请注意，你应该根据你的操作系统版本和 PostgreSQL 版本替换上述链接中的 EL-7-x86_64。 安装 PostgreSQL：使用以下命令来安装 PostgreSQL，假设你要安装的是 PostgreSQL 13： 1sudo yum install postgresql13 postgresql13-server 初始化 PostgreSQL：安装完成后，你需要初始化 PostgreSQL 数据库。这可以通过运行以下命令完成： 1/usr/pgsql-13/bin/postgresql-13-setup initdb 启动 PostgreSQL：然后，你需要启动 PostgreSQL 服务： 1sudo systemctl start postgresql-13 设置 PostgreSQL 开机启动：如果你想在系统启动时自动启动 PostgreSQL，你可以运行： 1sudo systemctl enable postgresql-13 登录到 PostgreSQL：PostgreSQL 创建了一个名为 postgres 的系统用户和数据库用户。你可以切换到 postgres 用户然后使用 psql 命令行工具： 1sudo -u postgres psql 此时，你应该已经成功在你的系统上安装了 PostgreSQL，并且可以开始使用它了。这些步骤可能会因你的系统和你的具体需求而略有不同。如果你遇到任何问题，你应该查阅 PostgreSQL 的官方文档或者 CentOS 的社区帮助页面。 如果出现： 上次元数据过期检查：0:04:44 前，执行于 2023年05月30日 星期二 15时35分56秒。 所有的匹配结果均已经被参数的模块化过滤条件筛除: postgresql13 所有的匹配结果均已经被参数的模块化过滤条件筛除: postgresql13-server 错误：没有任何匹配: postgresql13 postgresql13-server 则： 如果你在使用基于 CentOS 的系统，你可以尝试使用下面的步骤来添加 PostgreSQL 官方的 Yum Repository： 导入 GPG Key： 1sudo rpm --import https://download.postgresql.org/pub/repos/yum/RPM-GPG-KEY-PGDG 添加 Yum Repository： 根据你的 CentOS 版本（例如 CentOS 7），运行以下命令： 1sudo curl -o /etc/yum.repos.d/pgdg.repo https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm 请注意，你需要替换 EL-7-x86_64 来匹配你的系统版本和硬件架构。 禁用 PostgreSQL 模块： 为了防止软件包冲突，需要禁用 PostgreSQL 模块： 1sudo dnf -qy module disable postgresql 安装 PostgreSQL： 现在你可以尝试再次安装 PostgreSQL： 1sudo dnf install postgresql13 postgresql13-server 如果你的操作系统是 Fedora，你可能需要替换上述命令中的 dnf 为 yum，同时 dnf -qy module disable postgresql 可能也不需要。 如果上述步骤仍然不能解决问题，建议你查阅 PostgreSQL 的官方文档或者 CentOS 的社区帮助页面，获取更详细的安装帮助。","categories":[],"tags":[]},{"title":"mysql容器与本机挂载做持久化","slug":"mysql容器与本机挂载做持久化","date":"2024-01-13T11:48:26.000Z","updated":"2024-01-13T11:48:40.582Z","comments":true,"path":"2024/01/13/mysql容器与本机挂载做持久化/","permalink":"http://example.com/2024/01/13/mysql%E5%AE%B9%E5%99%A8%E4%B8%8E%E6%9C%AC%E6%9C%BA%E6%8C%82%E8%BD%BD%E5%81%9A%E6%8C%81%E4%B9%85%E5%8C%96/","excerpt":"","text":"mysql容器与本机挂载做持久化 要在Docker容器中运行的MySQL与本地MySQL数据共享并实现持久化，可以通过Docker数据卷（volumes）将本地文件系统上的目录挂载到MySQL容器中。以下是一些简单步骤来实现这个目标： 首先，在本地文件系统上创建一个目录，用于存储MySQL数据。例如，你可以创建一个名为mysql-data的目录： 1mkdir /mysql-data 这将在你的用户主目录下创建一个名为mysql-data的文件夹。 使用docker run命令运行一个新的MySQL容器，并使用-v（或--volume）选项将本地目录挂载到容器的/var/lib/mysql目录。这是MySQL容器中用于存储数据的默认目录。以下是一个运行MySQL容器的示例命令： 123456docker run -d \\ --name mysql-container \\ -p 3306:3306 \\ -e MYSQL_ROOT_PASSWORD=my-secret-pw \\ -v /mysql-data:/var/lib/mysql \\ mysql:latest 在这个例子中： -d：以分离模式运行容器。 --name mysql-container：为容器指定一个名称。 -p 3306:3306：将容器的3306端口映射到宿主机的3306端口。 -e MYSQL_ROOT_PASSWORD=my-secret-pw：设置MySQL root用户的密码。 -v ~/mysql-data:/var/lib/mysql：将本地目录~/mysql-data挂载到容器的/var/lib/mysql目录。 mysql:latest：使用的MySQL Docker镜像及其版本。 容器启动后，MySQL的数据文件将存储在本地~/mysql-data目录中。这意味着，即使你停止并删除容器，数据仍会保留在本地目录中。要在新的MySQL容器中使用相同的数据，只需使用相同的-v选项将本地目录挂载到新容器即可。 在容器中创建的数据库和表将在本地挂载的MySQL数据目录中可见。当你将本地目录（如~/mysql-data）挂载到容器的/var/lib/mysql目录时，容器中的MySQL实例将在这个目录中存储所有数据文件。当你在容器中创建一个新的数据库或表时，MySQL会在数据目录中创建相应的文件和文件夹。由于你已经将容器的数据目录挂载到了本地目录，因此你可以在本地目录中看到这些文件。对于每个创建的数据库，你将在数据目录中看到一个与数据库同名的文件夹。在这个文件夹中，你将找到该数据库中所有表的文件。文件的扩展名取决于表的存储引擎。例如，对于InnoDB存储引擎，表文件具有.ibd扩展名。","categories":[],"tags":[]},{"title":"Linux系统下配置DNS","slug":"Linux系统下配置DNS","date":"2024-01-13T11:47:12.000Z","updated":"2024-01-13T11:47:56.294Z","comments":true,"path":"2024/01/13/Linux系统下配置DNS/","permalink":"http://example.com/2024/01/13/Linux%E7%B3%BB%E7%BB%9F%E4%B8%8B%E9%85%8D%E7%BD%AEDNS/","excerpt":"","text":"2022年12月9日编写 yanhaochenLinux系统下配置DNS🤦‍♀️ 问题描述： 当Linux出现ping 域名无法识别，但是ping ip地址可以完全ping的通，这个原因是因为实际上就是这台服务器不能通过域名去访问，配置的所有跟域名相关的都无法解析，下载的链接提供的是域名的时候无法解析的 问题解决： 在Linux中 &#x2F;etc&#x2F;resol.conf 文件内编辑如下： 1nameserver 114.114.114.114 114.114.114.114 为中国电信的DNS，配置后任何域名都能够Ping的通","categories":[],"tags":[]},{"title":"Linux用户密码加密解密","slug":"Linux用户密码加密解密","date":"2024-01-13T11:46:11.000Z","updated":"2024-01-13T11:46:23.084Z","comments":true,"path":"2024/01/13/Linux用户密码加密解密/","permalink":"http://example.com/2024/01/13/Linux%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86%E8%A7%A3%E5%AF%86/","excerpt":"","text":"Linux用户密码加密解密 在linux系统下，用户的密码会保存在&#x2F;etc&#x2F;shadow中 即： 查看密码有两种方式：一个是&#x2F;etc&#x2F;passwd: x表示密码保存在&#x2F;etc&#x2F;shadow文件中 然后进入到shadow文件中，即可以看到密码是加密的 后面的19335表示天数，即上次密码修改，0 两次密码修改间隔，没有限制 99999 两次密码修改间隔最多天数没有限制 7 提前告知用户7天密码过期 :: 该用户永久可用密码 同样，密码的加密的格式为： 1$id$salt$encrypted id表示加密算法，salt为密码学的salt，encrypted表示密码hash 本主机的加密密码为： 1$6$zRszbIkv$sy98kMCtDd3u1w172q2r/yj7akruD1CmwxbLDQby2NikE/1O6Z0SQveKPNojahdY8z/szFFDvFfDGUz0WhSuk0 id为6 表示加密为sha512加密，5代表sha256，6代表sha512 解密可以使用kali的hashcat进行暴力破解","categories":[],"tags":[]},{"title":"Linux下的postfix邮件服务器搭建","slug":"Linux下的postfix邮件服务器搭建","date":"2024-01-13T11:45:36.000Z","updated":"2024-01-13T11:45:49.322Z","comments":true,"path":"2024/01/13/Linux下的postfix邮件服务器搭建/","permalink":"http://example.com/2024/01/13/Linux%E4%B8%8B%E7%9A%84postfix%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/","excerpt":"","text":"Linux下的postfix邮件服务器搭建 1.先准备开启邮件服务器的端口，25端口（SMTP)用来发送邮件，110（pop3，用来接收邮件），143（imap服务，用于接收邮件） 12firewall-cmd --zone=public --add-port=25/tcp --permanent (110,143)firewall-cmd --reload 或者直接关闭防火墙（不推荐） 1systemctl stop firewalld 关闭selinux 1vim /etc/selinux/config 改为disabled 2.修改主机名 将主机名改为邮件服务器域名,如 mail.testmail.com 1hostnamectl set-hostname mail.testmail.com 3.安装DNS服务 1yum install bind 编辑DNS配置文件 1vim /etc/named.conf 配置子配置文件 1vim /etc/named.rfc1912.zones 1systemctl start named 进入DNS服务器区域配置文件目录 1cd /var/named 复制模板区域配置文件为指定区域配置文件 12cp -p named.localhost testmail.com.zonecp -p named.localhost testmail.com.local 编辑正向区域配置文件 1vim testmail.com.zone 编辑反向区域配置文件 1vim testmail.com.local 启动DNS域名解析服务器 1systemctl restart named 4.安装nslookup命令 1yum -y install bind-utils 将本机的DNS指向自己的DNS服务器 1vim /etc/resolv.conf 解析邮件服务器地址： 1nslookup mail.testmail.com 5.安装Postfix 一般centos系统自带postfix 检测postfix是否支持cyrus dovecot功能 1postconf -a *** 如果出现：libmysqlclient.so.18: cannot open shared object file: No such file or directory**** 则需要安装mysql-mariadb： 1yum install -y dovecot mariadb-server dovecot-mysql 然后编辑POSTFIX配置文件 1vim /etc/postfix/main.cf 检查postfix有没有错误，无输出就是没有错了，当然输出warring也无所谓而已，不影响后续结果 1postfix check 启动postfix 1systemctl start postfix 6.测试 添加邮件账号组 1groupadd mailusers 再添加两个测试邮件服务账号： 12useradd -g mailusers -s /sbin/nologin longpasswd long 12useradd -g mailusers -s /sbin/nologin jackpasswd jack 远程telent登录测试 1telnet mail.testmail.com 25 检查是否收到邮件 cd /home/jack/Maildir/new/ 7.测试给公网发送邮件 安装mailx服务 1yum -y install mailx 测试给公网发送邮件： 发送成功，一般都在垃圾邮箱里面，哈哈哈 end-2023&#x2F;2&#x2F;15-yanhaochen","categories":[],"tags":[]},{"title":"Linux基础","slug":"Linux基础","date":"2024-01-13T11:44:56.000Z","updated":"2024-01-13T11:45:13.171Z","comments":true,"path":"2024/01/13/Linux基础/","permalink":"http://example.com/2024/01/13/Linux%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Linux基础 1.显示日期与时间的指令：data date +%Y/%m/%d date +%H:%H 2.显示日历 cal cal [month] [year] ，例如 ：cal 13 2015 3.简易计算器 bc 4.离开 ctrl + d 相当于exit 5.用shift + 上下键 用来代替滚轮 6.同步使用硬盘的指令:sync 7.取消关机 shutdown -c 8.获取文件的md5指纹(数字签名) md5sum 文件名 9.文本内容的查看命令: cat 文件名 less 文件名 (以分页的形式浏览文件信息),上箭头 为上一行 下箭头 为下一行 G最后一行 g第一页 &#x2F;关键字(搜索关键字) q退出 tali, tail -n 20 文件名 # 显示文件的最后20行信息 10.文件查找 find 搜索路径 -name \"文件名关键词\" 11.软连接和硬连接 硬ls 软 ls -s ln -s 目标文件或文件夹 软连接名字 硬连接，根据索引来进行连接，而软连接相当于windows的快捷方式，一种快速定位 12.进程 ps -aux 静态查看进程 top 动态查看进程 13.关闭进程 kill -9 进程id 强制关闭进程 14.覆盖写入&gt; 追加写入 &gt;&gt; 15.管道分隔符： 查找aries组：cat /etc/group | grep -n “baizhi” 16.系统权限： groupadd 组名 创建用户组 groupdel 组名 删除用户组 查找系统中的组 cat /etc/group | grep -n “组名”` 设置密码 ： passwd 17.压缩和解压: tar -zcvf 压缩后文件名 被压缩文件 压缩 tar -zxvf 压缩文件名 -C 解压后文件所在目录 解压 18.运行rpm文件: rpm文件相当于windows中的exe 安装 ：rpm -ivh xxx.rpm 查看系统中是否安装过rpm：rpm -qa 软件名 卸载 : rpm -e xxx.rpm Linux基本配置文件 环境变量配置文件 :/etc/profile 网络配置环境：/etc/sysconfig/network-scripts/ifcfg-ens33 ip地址与主机映射配置文件 /etc/hosts 用户与用户组的配置文件 /ect/passwd 该配置文件包含了用户信息 /etc/shadow 存储了用户密码的相关信息 /etc/group存储着组的相关信息 /etc/rc 启动，或改变运行级的scripts /etc/fstab 自动mount文件系统列表 /etc/inittab init的配置文件 12/etc/profile , /etc/csh.login ,/etc/csh.cshrc 登录或启动时Bourne或Cshells执行的文件.这允许系统管理员为所有用户建立全局缺省环境. 1234567/etc/securetty 确认安全终端，即哪个终端允许root登录.一般只列出虚拟控制台，这样就不可能(至少很困难)通过modem或网络闯入系统并得到超级用户特权. /etc/shells 列出可信任的shell.chsh 命令允许用户在本文件指定范围内改变登录shell.提供一台机器FTP服务的服务进程ftpd检查用户shell是否列在 /etc/shells 文件中，如果不是将不允许该用户登录. /etc/termcap 终端性能数据库.说明不同的终端用什么&quot;转义序列&quot;控制.写程序时不直接输出转义序列(这样只能工作于特定品牌的终端)，而是从/etc/termcap中查找要做的工作的正确序列.这样，多数的程序可以在多数终端上运行 init进程，由内核启动的用户级进程，一般为sbin&#x2F;init linux启动，POST（加电检测）-&gt; 加载BIOS -&gt;确定启动设备，加载boot loader -&gt; 加载内核 kernel 初始化initrd -&gt; 运行&#x2F;sbin&#x2F;init -&gt;打印用户登录提示符 Linux磁盘分区 目录 &#x2F; 建议大小 150G-200G ext4 swap 1024mb &#x2F;boot 1G左右 &#x2F;tmp 5G左右 &#x2F;home 尽量大些 开启防火墙： firewall-cmd --zone=public --add-port=3306/tcp --permanent 查看centos的系统版本号cat /etc/redhat-release系统信息 uname -a查看系统是32位还是64位 arch查看cpu配置 lscpu","categories":[],"tags":[]},{"title":"Linux安装zookeeper","slug":"Linux安装zookeeper","date":"2024-01-13T11:43:50.000Z","updated":"2024-01-13T11:44:28.967Z","comments":true,"path":"2024/01/13/Linux安装zookeeper/","permalink":"http://example.com/2024/01/13/Linux%E5%AE%89%E8%A3%85zookeeper/","excerpt":"","text":"Linux安装zookeeper 1.自行先找到下载链接：自己安装安装包 Index of &#x2F;dist&#x2F;zookeeper (apache.org) 2.解压 tar -zxvf xxxx.tar.gz 3.进入conf文件 cp zoo_simple.cfg zoo.cfg 4.配置环境变量 vi /etc/profile 123export ZOOKEEPER_HOME=指定安装目录export PATH=$ZOOKEEPER_HOME/bin:$PATHexport PATH 然后 source profile 生效 5.启动服务 zkServer.sh start 6.查看状态 zkServer.sh status Linux安装kafka 1.先去官网，下载所需要的安装包： Apache Kafka 然后tar -zxvf kafkaxxxx.tgz cd /data/kafka/kafka_2.13-3.3.1 2.运行kafka: bin/kafka-server-start.sh config/server.properties & 启动kafka时候必须先启动zookeeper ！！！！！ 3.查看jps: 或者jps -ml 4.查看kafka进程","categories":[],"tags":[]},{"title":"Linux安装NoSQL(Redis)","slug":"Linux安装NoSQL-Redis","date":"2024-01-13T11:43:12.000Z","updated":"2024-01-13T11:43:28.281Z","comments":true,"path":"2024/01/13/Linux安装NoSQL-Redis/","permalink":"http://example.com/2024/01/13/Linux%E5%AE%89%E8%A3%85NoSQL-Redis/","excerpt":"","text":"Linux安装NoSQL(Redis) 首先先进行软件安装包下载: 123wget http://download.redis.io/releases/redis-5.0.4.tar.gztar -zxvf redis-5.0.4.tar.gzcd redis-5.0.4 进入目录后，然后make 1make 二进制文件是编译完成后在src目录下 12cd src./redis-server 服务端 启动服务端后，然后启动客户端验证: 1./redis-cli","categories":[],"tags":[]},{"title":"kafka集群安装","slug":"kafka集群安装","date":"2024-01-13T11:42:28.000Z","updated":"2024-01-13T11:42:42.762Z","comments":true,"path":"2024/01/13/kafka集群安装/","permalink":"http://example.com/2024/01/13/kafka%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/","excerpt":"","text":"Zookeeper & Kafka集群安装和测试 之前的教程是kafka和zookeeper的单价版安装，现在有了三台服务器，开始部署kafka的集群安装版本 首先先进行zookeeper的集群测试，目前有了三台服务器，分别是 192.168.100.112 192.168.100.110 192.168.100.109 这三个服务器都安装了，zookeeper和kafka，然后给三台服务器分别配置如下的内容： 12345678910111213141516171819202122232425262728293031323334353637383940#The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/tmp/zookeeper# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1## Metrics Providers## https://prometheus.io Metrics Exporter#metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider#metricsProvider.httpHost=0.0.0.0#metricsProvider.httpPort=7000#metricsProvider.exportJvmInfo=trueserver.1=192.168.100.112:3188:3288server.2=192.168.100.109:3188:3288server.3=192.168.100.110:3188:3288 然后请注意dataDir 的路径，你自己可以自行配置，但是一般不建议修改它，找到&#x2F;tmp&#x2F;zookeeper为例 在这里创建一个myid，分别写入1，2，3 1echo &quot;1&quot;&gt;myid #192.168.100.112 1echo &quot;2&quot;&gt;myid #192.168.100.109 1echo &quot;3&quot;&gt;myid #192.168.100.110 分别写入后，三台服务器都启动zookeeper服务，一般会出现leader 和 follower 12./zkServer.sh start./zkServer.sh status 集群准备 zookeeper192.168.100.112 –follower id&#x3D;1192.168.100.110 –follower id&#x3D;3192.168.100.109 –leader id&#x3D;2 这些leader和follower是通过选举算法来进行确定的。 zookeeper启动后，现在来启动kafka 这三台服务器都有kafka，先要保证kafka的版本一致性，然后进入config文件进入，server.properties 文件编辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139![kafka2](C:\\Users\\yanhaochen\\xhy-ops-document\\doc\\kafka2.png)# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the &quot;License&quot;); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.## This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.# See kafka.server.KafkaConfig for additional details and defaults############################## Server Basics ############################## The id of the broker. This must be set to a unique integer for each broker.broker.id=3############################# Socket Server Settings ############################## The address the socket server listens on. If not configured, the host name will be equal to the value of# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.# FORMAT:# listeners = listener_name://host_name:port# EXAMPLE:# listeners = PLAINTEXT://your.host.name:9092#listeners=PLAINTEXT://:9092listeners=PLAINTEXT://192.168.100.110:9092# Listener name, hostname and port the broker will advertise to clients.# If not set, it uses the value for &quot;listeners&quot;.#advertised.listeners=PLAINTEXT://your.host.name:9092# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL# The number of threads that the server uses for receiving requests from the network and sending responses to the networknum.network.threads=3# The number of threads that the server uses for processing requests, which may include disk I/Onum.io.threads=8# The send buffer (SO_SNDBUF) used by the socket serversocket.send.buffer.bytes=102400# The receive buffer (SO_RCVBUF) used by the socket serversocket.receive.buffer.bytes=102400# The maximum size of a request that the socket server will accept (protection against OOM)socket.request.max.bytes=104857600############################# Log Basics ############################## A comma separated list of directories under which to store log fileslog.dirs=/data/kafka/kafka_2.12-3.3.1/kafka-logs# The default number of log partitions per topic. More partitions allow greater# parallelism for consumption, but this will also result in more files across# the brokers.num.partitions=1# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.# This value is recommended to be increased for installations with data dirs located in RAID array.num.recovery.threads.per.data.dir=1############################# Internal Topic Settings ############################## The replication factor for the group metadata internal topics &quot;__consumer_offsets&quot; and &quot;__transaction_state&quot;# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1############################# Log Flush Policy ############################## Messages are immediately written to the filesystem but by default we only fsync() to sync# the OS cache lazily. The following configurations control the flush of data to disk.# There are a few important trade-offs here:# 1. Durability: Unflushed data may be lost if you are not using replication.# 2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.# 3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.# The settings below allow one to configure the flush policy to flush data after a period of time or# every N messages (or both). This can be done globally and overridden on a per-topic basis.# The number of messages to accept before forcing a flush of data to disk#log.flush.interval.messages=10000# The maximum amount of time a message can sit in a log before we force a flush#log.flush.interval.ms=1000############################# Log Retention Policy ############################## The following configurations control the disposal of log segments. The policy can# be set to delete segments after a period of time, or after a given size has accumulated.# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens# from the end of the log.# The minimum age of a log file to be eligible for deletion due to agelog.retention.hours=168# A size-based retention policy for logs. Segments are pruned from the log unless the remaining# segments drop below log.retention.bytes. Functions independently of log.retention.hours.#log.retention.bytes=1073741824# The maximum size of a log segment file. When this size is reached a new log segment will be created.#log.segment.bytes=1073741824# The interval at which log segments are checked to see if they can be deleted according# to the retention policieslog.retention.check.interval.ms=300000############################# Zookeeper ############################## Zookeeper connection string (see zookeeper docs for details).# This is a comma separated host:port pairs, each corresponding to a zk# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.# You can also append an optional chroot string to the urls to specify the# root directory for all kafka znodes.#zookeeper.connect=localhost:2181# Timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=18000zookeeper.connect=192.168.100.112:2181,192.168.100.109:2181,192.168.100.110:2181############################# Group Coordinator Settings ############################## The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.# The default value for this is 3 seconds.# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.group.initial.rebalance.delay.ms=0 broker.id&#x3D; 就是kafka集群的标识号，listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;192.168.100.110:9092 是内网通信的监听IP，如何要进行外网的话，则用advertised.listeners 另外再加上 zookeeper.connect&#x3D;192.168.100.112:2181,192.168.100.109:2181,192.168.100.110:2181 不同服务器，配置不同的broker.id号，这里我和zookeeper保持一致 集群准备 kafka192.168.100.112 id&#x3D;1192.168.100.110 id&#x3D;3192.168.100.109 id&#x3D;2 准备好以后启动三台机器启动kafka,如果其中一台没有关闭防火墙的话,则会出现:java.net.NoRouteToHostException: 没有到主机的路由, 如果配置文件错误的话,启动两台后,其中一台会疯狂刷错误 现在…启动: 如果启动成功的话,三个界面会同时出现三个一致的画面,太长了,不截图了 ***测试kafka集群:*测试服务器:192.168.100.109 12bin/kafka-topics.sh --bootstrap-server 192.168.100.109:9092 --create --topic talking --partitions 1#新版要用bootstrap启动,老版用zookeeper-server 列出主题 1bin/kafka-topics.sh --bootstrap-server 192.168.100.109:9092 --list 产生消费者 1bin/kafka-console-producer.sh --broker-list 192.168.100.109:9092 --topic talking 测试可以是否消费数据 1bin/kafka-console-consumer.sh --bootstrap-server 192.168.100.109:9092 --topic talking --from-beginning","categories":[],"tags":[]},{"title":"git使用","slug":"git使用","date":"2024-01-13T11:41:52.000Z","updated":"2024-01-13T11:42:04.182Z","comments":true,"path":"2024/01/13/git使用/","permalink":"http://example.com/2024/01/13/git%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Git 操作 在创建分支前，确保在master分支，要保证当前代码最新 1git pull origin master 创建分支 1git branch test 切换新的分支 1git checkout test 把本地分支推到远端，让git远端也有一个分支 1git push origin test 初始化 1git init 克隆下载代码 1git clone xxxxx.git 查看分支 1git branch 合并分支 12345#首先查看在那个分支上面，如果主分支master新建立了dev ，dev下又有一个test，想合并test到dev上git branch#然后切换分支git checkout devgit merge test #将test合并到dev分支上 删除分支 1234#删除本地分支 git branch -d test#删除远端分支git push origin --delete test 提交代码我一般使用: TortoiseGit","categories":[],"tags":[]},{"title":"Docker的安装与方法，并且更改目录","slug":"Docker的安装与方法，并且更改目录","date":"2024-01-13T11:41:16.000Z","updated":"2024-01-13T11:41:29.638Z","comments":true,"path":"2024/01/13/Docker的安装与方法，并且更改目录/","permalink":"http://example.com/2024/01/13/Docker%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E6%96%B9%E6%B3%95%EF%BC%8C%E5%B9%B6%E4%B8%94%E6%9B%B4%E6%94%B9%E7%9B%AE%E5%BD%95/","excerpt":"","text":"Docker的安装与方法，并且更改目录😁 1.首先先下载离线安装包 Index of linux&#x2F;static&#x2F;stable&#x2F;x86_64&#x2F; (docker.com) 2.上传安装包并且解压 3.复制可执行文件到/usr/bin/ cp docker/* /usr/bin/ 4.将docker注册为service服务 vim /etc/systemd/system/docker.service 将docker.service写入下面内容： 123456789101112131415161718192021222324252627282930313233[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.serviceWants=network-online.target [Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStart=/usr/bin/dockerd --selinux-enabled=false --insecure-registry=127.0.0.1ExecReload=/bin/kill -s HUP $MAINPID# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinity# Uncomment TasksMax if your systemd version supports it.# Only systemd 226 and above support this version.#TasksMax=infinityTimeoutStartSec=0# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=process# restart the docker process if it exits prematurelyRestart=on-failureStartLimitBurst=3StartLimitInterval=60s [Install]WantedBy=multi-user.target 5.赋予service文件执行权限 chmod +x /etc/systemd/system/docker.service 6.重新加载配置 systemctl deamon-reload 7.启动 docker -v 更改Docker的安装路径💕 查看Docker的安装和存储路径： sudo docker info | grep \"Docker Root Dir\" 修改本机的安装目录： 1.先停止docker systemctl stop docker.socket systemctl stop docker 2.移动docker所有文件 mv /var/lib/docker /data/docker 3.建立软连接 ln -s /data/docker /var/lib/docker 4.重启docker systemctl restart docker Docker部署前后端项目 首先先获得一个java项目的jar包,另外pull一下jdk的镜像 在同一个目录下创建Dockerfile,目录随你放置。 Dockerfile内容FROM openjdk:17-jdk VOLUME /tmp COPY app.jar app.jar ENV TZ=Asia/Shanghai RUN bash -c &#39;touch /app.jar&#39; ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] 然后使用docker命令打包： docker build -t test . 使用docker run命令创建并且运行容器： docker run -d --name test -p 8001:8001 test docker ps -a 停止 docker stop 镜像id 前端就简单啦，如果用nginx的话，首先先pull一下nginx的镜像 然后同上。","categories":[],"tags":[]},{"title":"firewalld服务和docker冲突问题","slug":"firewalld服务和docker冲突问题","date":"2024-01-13T11:40:25.000Z","updated":"2024-01-13T11:40:42.456Z","comments":true,"path":"2024/01/13/firewalld服务和docker冲突问题/","permalink":"http://example.com/2024/01/13/firewalld%E6%9C%8D%E5%8A%A1%E5%92%8Cdocker%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"firewalld服务和docker冲突问题 在centos7中的防火墙服务是firewall的，firewall的底层是使用iptables进行数据过滤的，firewall只是防火墙的管理程序，而真正的防火墙内核则是Netfilter 当firewalld启动或者重启的时候，将会从iptables移除docker的规则，docker启动的连接链docker 被firewall清理了。如果使用是Systemd(systemctl)时候，firewalld会在docker之前启动，但是如果是在docker启动之后再启动firewalld，则需要重新docker进程了。","categories":[],"tags":[]},{"title":"Debian系统的优化","slug":"Debian系统的优化","date":"2024-01-13T11:38:42.000Z","updated":"2024-01-13T11:38:55.203Z","comments":true,"path":"2024/01/13/Debian系统的优化/","permalink":"http://example.com/2024/01/13/Debian%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BC%98%E5%8C%96/","excerpt":"","text":"Debian系统的优化 一.更新软件源 12sudo apt updatesudo apt upgrade 确保Debian系统为最新，我的系统为Debian12 ,12 为最新 如果更新源太慢，可以在/etc/apt/sources.list 文件中，替换apt源为国内源，这里推荐使用腾讯云源，虽然图片中使用清华源，但是太慢 12345678deb https://mirrors.tencent.com/debian/ bookworm main non-free non-free-firmware contribdeb-src https://mirrors.tencent.com/debian/ bookworm main non-free non-free-firmware contribdeb https://mirrors.tencent.com/debian-security/ bookworm-security maindeb-src https://mirrors.tencent.com/debian-security/ bookworm-security maindeb https://mirrors.tencent.com/debian/ bookworm-updates main non-free non-free-firmware contribdeb-src https://mirrors.tencent.com/debian/ bookworm-updates main non-free non-free-firmware contribdeb https://mirrors.tencent.com/debian/ bookworm-backports main non-free non-free-firmware contribdeb-src https://mirrors.tencent.com/debian/ bookworm-backports main non-free non-free-firmware contrib 执行完以后，然后sudo apt update然后sudo apt upgrade 使用国内源好处就是下载软件速度快 另外清理不必要的软件包和无用的软件包： 12345# 清理无用的软件包sudo apt autoremove# 清理下载的软件包缓存sudo apt clean 二，关闭不必要的服务，只启动必要的服务 查看所有的服务状态： 1systemctl list-units --type=service 禁用某个服务： 1sudo systemctl disable xxxx 三，使用SSD存储 使用SSD存储：如果可能，将系统安装在SSD上，这将显著提高系统的响应速度","categories":[],"tags":[]},{"title":"Linux安装入侵检测系统IDS","slug":"Linux安装入侵检测系统IDS","date":"2024-01-13T11:37:37.000Z","updated":"2024-01-13T11:37:50.047Z","comments":true,"path":"2024/01/13/Linux安装入侵检测系统IDS/","permalink":"http://example.com/2024/01/13/Linux%E5%AE%89%E8%A3%85%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9FIDS/","excerpt":"","text":"Linux安装入侵检测系统IDS 1.首先先安装gcc: yum install -y gcc inotify-tools bind-utils 2.通过命令： wget -O ossec.2.9.3.tar.gz https://github.com/ossec/ossec-hids/archive/2.9.3.tar.gz 下载完成后解压操作： tar -zxvf ossec.2.9.3.tar.gz 执行: 首先先个一个读写权限 chmod +x install.sh ./install.sh 安装完成后会出现一个选择语言的选项： 选择cn 已经装了gcc了，就继续 本博主是本机安装的，直接就选local 一路y，直到白名单，选择n 安装完成后 在/var/ossec/bin/ossec-control start里面启动 所有的警告都会存放于/var/ossec/logs/alerts","categories":[],"tags":[]},{"title":"利用Docker -compose部署前后端项目","slug":"利用Docker-compose部署前后端项目","date":"2024-01-13T11:36:48.000Z","updated":"2024-01-13T11:37:08.678Z","comments":true,"path":"2024/01/13/利用Docker-compose部署前后端项目/","permalink":"http://example.com/2024/01/13/%E5%88%A9%E7%94%A8Docker-compose%E9%83%A8%E7%BD%B2%E5%89%8D%E5%90%8E%E7%AB%AF%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"利用Docker -compose部署前后端项目 Docker Compose 是 Docker 官方提供的一个工具，可以通过简单的 YAML 文件来定义和运行多个 Docker 容器应用 好处如下： 简化部署：使用 Docker Compose 可以一次性启动多个容器，包括数据库、消息队列、应用程序等，并可以按需配置容器之间的网络、卷等，从而简化了部署过程。 标准化部署：使用 Docker Compose 部署应用程序可以保证容器的环境和依赖项的一致性，从而确保应用程序在任何地方都可以运行。 管理容器：使用 Docker Compose 可以轻松地启动、停止、删除容器，从而方便管理容器。 扩展应用程序：使用 Docker Compose 可以轻松地扩展应用程序，例如添加新的容器、配置负载均衡等。 节省时间：使用 Docker Compose 可以节省配置和部署应用程序的时间，从而更快地推出新功能和更新。 下面利用编写docker-compose.yml文件来进行部署 首先在&#x2F;opt&#x2F;test&#x2F;文件夹里创建一个docker-compose.yml 1touch docker-compose.yml 里面编写： 12345678910111213141516171819version: &quot;3&quot;services: web: image: nginx:latest ports: - &quot;80:80&quot; volumes: - /opt/test/build/framing:/usr/share/nginx/html - /opt/test/nginx.conf:/etc/nginx/nginx.conf restart: always backend: image: openjdk:17-jdk ports: - &quot;9940:9940&quot; volumes: - /opt/test/demo/app.jar:/app.jar command: [&quot;java&quot;, &quot;-jar&quot;, &quot;app.jar&quot;,&quot;--server.port=9940&quot;] restart: always 从这个docker-compose.yml看起来，其中web服务映射到80端口，backend服务映射到9940端口，并将本地的&#x2F;app.jar文件映射到了容器内的&#x2F;app.jar文件。另外，backend服务的command指令可以保证在容器启动后直接运行app.jar文件。 前端在build文件里，后端app.jar在demo里 最后运行： 1docker-compose up或者docker-compose up --build 另外的docker compose其他命令： 123456789docker-compose up: 启动所有定义的服务，如果服务不存在则自动构建。docker-compose up &lt;service_name&gt;: 启动指定服务。docker-compose down: 关闭所有服务，移除所有容器、网络和卷。docker-compose ps: 列出正在运行的容器。docker-compose logs: 显示服务日志。docker-compose restart: 重启所有服务。docker-compose stop: 停止所有服务。docker-compose build: 构建镜像。docker-compose exec &lt;service_name&gt; &lt;command&gt;: 在指定服务上运行命令。例如：docker-compose exec webserver bash 可以在名为 webserver 的服务上运行 bash 命令。","categories":[],"tags":[]},{"title":"磁盘管理","slug":"磁盘管理","date":"2024-01-13T11:36:09.000Z","updated":"2024-01-13T11:36:29.591Z","comments":true,"path":"2024/01/13/磁盘管理/","permalink":"http://example.com/2024/01/13/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/","excerpt":"","text":"Linux磁盘：如何把一块磁盘挂载😍 首先先执行dh -h，查看电脑的硬盘信息,如果磁盘没有挂载的话就无法显示 1.dh -h 再使用fdisk -l查看所有磁盘信息包括未加载的磁盘 2.fdisk -l 然后再查看磁盘挂载的区域 3.lsblk 接下来就是分区的操作了，首先用fdisk进行分区 4.fdisk /dev/sdb 这里的&#x2F;dev&#x2F;sdb是为挂载的磁盘信息，以你自己的为例， 执行完以后，会出现提示信息，按照本教程依次选择：m –&gt; n –&gt; p –&gt; 1 –&gt; wq的操作 另外重读分区表 5.partprobe /dev/sdb 好了，接下来就是用mkf4创建新的文件系统啦，在linux中比较常见是就是ext4文件系统 6.mkfs.ext4 /dev/sdb1 这里要注意的是sdb1而不是sdb，因为前面已经格式化过了，所以sdb1也就是sdb 然后创建要挂载的目录,下面以创建data为例 7.mkdir /data 使用mount来进行目录的挂载 8.mount /dev/sdb1 /data 到这部已经成功挂载，但是这个只是暂时的，如果重启，白弄。 编辑 /etc/fstab 永久挂载目录 vi &#x2F;etc&#x2F;fstab 进入后加入一条： /dev/sdb1 /data ext4 defaults 0 0 然后就成功啦 ​","categories":[],"tags":[]},{"title":"部署php项目","slug":"部署php项目","date":"2024-01-13T11:35:21.000Z","updated":"2024-01-13T11:35:34.897Z","comments":true,"path":"2024/01/13/部署php项目/","permalink":"http://example.com/2024/01/13/%E9%83%A8%E7%BD%B2php%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"部署php 要在Ubuntu系统上安装并运行PHP，你需要遵循以下步骤。这些步骤适用于大多数版本的Ubuntu，包括最新的版本。但是，确保你根据你的具体情况进行适当的调整。 更新软件包索引： 首先，打开终端并运行以下命令以更新软件包索引： 1sudo apt update 安装PHP： 然后，你可以使用apt命令安装PHP。在这个例子中，我们将安装PHP 7.4，但你可以根据需要选择其他版本： 1sudo apt install php 验证安装： 安装完成后，你可以通过运行以下命令来验证PHP是否已成功安装： 1php -v 这将显示你安装的PHP版本信息。 安装PHP模块（可选）： 你可能还需要安装一些PHP模块，例如MySQL模块或者GD模块。这些模块可以通过apt命令进行安装，例如： 1sudo apt install php-mysql php-gd 安装并配置Web服务器（例如，Apache）： 为了让你的PHP代码在Web服务器上运行，你需要安装并配置一个Web服务器。例如，你可以安装Apache： 1sudo apt install apache2 libapache2-mod-php 然后，你需要重启Apache以使更改生效： 1sudo systemctl restart apache2 创建PHP文件进行测试： 在Apache的文档根目录（通常是/var/www/html）中，创建一个.php文件进行测试： 1sudo echo &quot;&lt;?php phpinfo(); ?&gt;&quot; &gt; /var/www/html/info.php 然后，打开Web浏览器并访问http://localhost/info.php，你应该能看到一个页面，其中包含了PHP的详细信息，这表示PHP已经成功安装并在Web服务器上运行。 以上就是在Ubuntu系统上安装并运行PHP的步骤。请记住，根据你的具体需求和环境，你可能需要进行一些其他的配置和优化。","categories":[],"tags":[]},{"title":"nginx安装","slug":"nginx安装","date":"2024-01-13T11:34:34.000Z","updated":"2024-01-13T11:34:46.571Z","comments":true,"path":"2024/01/13/nginx安装/","permalink":"http://example.com/2024/01/13/nginx%E5%AE%89%E8%A3%85/","excerpt":"","text":"Linux安装nginx cd /data wget https://nginx.org/download/nginx-1.21.2.tar.gz # 下载安装包，版本请自行选择 tar -zxvf nginx-1.21.2.tar.gz cd ./ngix-1.21.2 ./configure --prefix=/data/nginx make && make install cd /sbin/nginx 配置环境变量： export PATH=$PATH:/data/nginx/sbin 如果提示错误： fuser -k 80/tcp #关闭占用80端口的程序 再运行。 解决nginx部署项目后刷新提示404页面 123location / &#123; try_files $uri $uri/ /index.html; &#125; 在nginx中conf中配置有个index页面中","categories":[],"tags":[]},{"title":"安装kong/konga","slug":"安装kong-konga","date":"2024-01-13T11:33:37.000Z","updated":"2024-01-13T13:06:23.811Z","comments":true,"path":"2024/01/13/安装kong-konga/","permalink":"http://example.com/2024/01/13/%E5%AE%89%E8%A3%85kong-konga/","excerpt":"","text":"安装kong和konga 本文档推荐在docker中运行 一：安装kong 创建自定义 Docker 网络以允许容器发现和相互沟通: 1docker network create kong-net 启动一个 PostgreSQL 容器： 1234567docker run -d --name kong-database \\ --network=kong-net \\ -p 5432:5432 \\ -e &quot;POSTGRES_USER=kong&quot; \\ -e &quot;POSTGRES_DB=kong&quot; \\ -e &quot;POSTGRES_PASSWORD=kongpass&quot; \\ postgres:13 POSTGRES_USER和 ：将这些值设置为 。这是 孔网关所需的默认值。POSTGRES_DB``kong POSTGRES_PASSWORD：将数据库密码设置为任意字符串。 在此示例中，名为 Postgres 的容器可以 与网络上的任何容器通信。kong-database``kong-net 准备 Kong 数据库： 123456docker run --rm --network=kong-net \\ -e &quot;KONG_DATABASE=postgres&quot; \\ -e &quot;KONG_PG_HOST=kong-database&quot; \\ -e &quot;KONG_PG_PASSWORD=kongpass&quot; \\ -e &quot;KONG_PASSWORD=test&quot; \\kong/kong-gateway:3.3.1.0 kong migrations bootstrap KONG_DATABASE： 指定 Kong 正在使用的数据库的类型。 KONG_PG_HOST： 上一步中通过网络进行通信的 Postgres Docker 容器的名称。kong-net KONG_PG_PASSWORD： 在 上一步。 KONG_PASSWORD（仅限企业版）：管理员的默认密码 金刚网关的超级用户。 执行以下命令，使用kong网关启动容器: 12345678910111213141516171819202122docker run -d --name kong-gateway \\ --network=kong-net \\ -e &quot;KONG_DATABASE=postgres&quot; \\ -e &quot;KONG_PG_HOST=kong-database&quot; \\ -e &quot;KONG_PG_USER=kong&quot; \\ -e &quot;KONG_PG_PASSWORD=kongpass&quot; \\ -e &quot;KONG_PROXY_ACCESS_LOG=/dev/stdout&quot; \\ -e &quot;KONG_ADMIN_ACCESS_LOG=/dev/stdout&quot; \\ -e &quot;KONG_PROXY_ERROR_LOG=/dev/stderr&quot; \\ -e &quot;KONG_ADMIN_ERROR_LOG=/dev/stderr&quot; \\ -e &quot;KONG_ADMIN_LISTEN=0.0.0.0:8001&quot; \\ -e &quot;KONG_ADMIN_GUI_URL=http://localhost:8002&quot; \\ -e KONG_LICENSE_DATA \\ -p 8000:8000 \\ -p 8443:8443 \\ -p 8001:8001 \\ -p 8444:8444 \\ -p 8002:8002 \\ -p 8445:8445 \\ -p 8003:8003 \\ -p 8004:8004 \\ kong/kong-gateway:3.3.1.0 --name和：要创建的容器的名称， 以及它所通信的 Docker 网络。--network KONG_DATABASE： 指定 Kong 正在使用的数据库的类型。 KONG_PG_HOST： 通过网络进行通信的 Postgres Docker 容器的名称。kong-net KONG_PG_USER和KONG_PG_PASSWORD： Postgres 用户名和密码。港通需要登录信息 将配置数据存储在数据库中。KONG_PG_HOST 所有_LOG参数：设置要输出到的日志的文件路径，或使用 将消息和错误打印到 和 的示例。stdout``stderr KONG_ADMIN_LISTEN： Kong 管理员 API 侦听请求的端口。 KONG_ADMIN_GUI_URL： （仅限企业版）用于访问 Kong 管理器的 URL，前面有一个协议 （例如，）。http:// KONG_LICENSE_DATA：（仅限企业版）如果您有许可证文件并已保存 作为环境变量，此参数从您的环境中提取许可证。 验证您的安装： 使用管理 API 访问端点：/services 1curl -i -X GET --url http://localhost:8001/services 您应该会收到一个状态代码。200 通过访问 Kong 管理器来验证它是否正在运行 使用中指定的 URL：KONG_ADMIN_GUI_URL 1http://localhost:8002 安装konga 启动PostgresSQL数据库启动konga PostgresSQL数据库。 1234567docker run -d --name konga-database \\ --network=kong-net \\ -p 5433:5432 \\ -e &quot;POSTGRES_USER=konga&quot; \\ -e &quot;POSTGRES_DB=konga&quot; \\ -e &quot;POSTGRES_PASSWORD=konga&quot; \\ postgres:9.6 初始化数据123456docker run --rm \\ --network=kong-net \\ pantsel/konga:latest \\ -c prepare \\ -a &quot;postgres&quot; \\ -u &quot;postgres://konga:konga@konga-database:5432/konga&quot; 启动Konga12345678docker run -d --name konga \\ --network kong-net \\ -e &quot;TOKEN_SECRET=secret123&quot; \\ -e &quot;DB_ADAPTER=postgres&quot; \\ -e &quot;DB_URI=postgres://konga:konga@konga-database:5432/konga&quot; \\ -e &quot;NODE_ENV=development&quot; \\ -p 1337:1337 \\ pantsel/konga 访问 IP+1337","categories":[],"tags":[]},{"title":"本地安装elasticsearch","slug":"本地安装elasticsearch","date":"2024-01-12T07:29:10.000Z","updated":"2024-01-12T07:43:19.171Z","comments":true,"path":"2024/01/12/本地安装elasticsearch/","permalink":"http://example.com/2024/01/12/%E6%9C%AC%E5%9C%B0%E5%AE%89%E8%A3%85elasticsearch/","excerpt":"","text":"本地安装elasticsearch 首先先从网络上下载最新的elasticsearch 1$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.8.2-linux-x86_64.tar.gz 下载完以后，进行解压操作 1$ tar -xzf elasticsearch-8.8.2-linux-x86_64.tar.gz 进入文件 1$ cd elasticsearch-8.8.2/bin 开始启动，注意，elasticsearch是不默认root启动的 需要创建一个用户 123$ adduser ela$ passwd ela$ chown -R ela elasticsearch/ 然后su ela启动 启动后在默认配置文件中config&#x2F;elasticsearch.yml中修改以下代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:##cluster.name: my-application## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:##node.name: node-1## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):##path.data: /path/to/data## Path to log files:##path.logs: /path/to/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:##bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## By default Elasticsearch is only accessible on localhost. Set a different# address here to expose this node on the network:##network.host: 192.168.0.1## By default Elasticsearch listens for HTTP traffic on the first free port it# finds starting at 9200. Set a specific HTTP port here:##http.port: 9200## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when this node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]##discovery.seed_hosts: [&quot;host1&quot;, &quot;host2&quot;]## Bootstrap the cluster using an initial set of master-eligible nodes:##cluster.initial_master_nodes: [&quot;node-1&quot;, &quot;node-2&quot;]## For more information, consult the discovery and cluster formation module documentation.## ---------------------------------- Various -----------------------------------## Allow wildcard deletion of indices:##action.destructive_requires_name: false#----------------------- BEGIN SECURITY AUTO CONFIGURATION -----------------------## The following settings, TLS certificates, and keys have been automatically# generated to configure Elasticsearch security features on 24-07-2023 11:28:48## --------------------------------------------------------------------------------# Enable security featuresxpack.security.enabled: falsexpack.security.enrollment.enabled: true# Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agentsxpack.security.http.ssl: enabled: false keystore.path: certs/http.p12# Enable encryption and mutual authentication between cluster nodesxpack.security.transport.ssl: enabled: true verification_mode: certificate keystore.path: certs/transport.p12 truststore.path: certs/transport.p12# Create a new cluster with the current node only# Additional nodes can still join the cluster latercluster.initial_master_nodes: [&quot;localhost.localdomain&quot;]# Allow HTTP API connections from anywhere# Connections are encrypted and require user authenticationhttp.host: 0.0.0.0http.port: 9200http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;# Allow other nodes to join the cluster from anywhere# Connections are encrypted and mutually authenticated#transport.host: 0.0.0.0#----------------------- END SECURITY AUTO CONFIGURATION ------------------------- 最后启动 .&#x2F;elasticsearch 并且开放端口9200 最后在浏览器中输入 localhost:9200即可部署成功","categories":[],"tags":[]},{"title":"安装docker compose","slug":"安装docker-compose","date":"2024-01-12T07:17:44.000Z","updated":"2024-01-12T07:18:12.793Z","comments":true,"path":"2024/01/12/安装docker-compose/","permalink":"http://example.com/2024/01/12/%E5%AE%89%E8%A3%85docker-compose/","excerpt":"","text":"安装docker compose 首先，请确保您已经安装了 Docker。如果没有，请访问 Docker 官网 获取适用于您操作系统的安装指南。 按照您的操作系统的指南安装 docker-compose： 对于 Linux： 请运行以下命令安装 docker-compose： 1sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 更改 docker-compose 的权限以使其可执行： 1sudo chmod +x /usr/local/bin/docker-compose 确认安装成功： 1docker-compose --version 对于 macOS： 如果您已经安装了 Homebrew，可以通过以下命令安装 docker-compose： 1brew install docker-compose 或者，您可以下载 Docker Desktop for Mac，其中包含 docker-compose。 对于 Windows： 对于 Windows 用户，建议安装 Docker Desktop for Windows。安装完成后，docker-compose 将自动包含在其中。 安装完成后，尝试再次运行 docker-compose。如果仍然出现命令未找到的错误，请检查可执行文件是否在您的系统 PATH 中。如果需要，您可以手动将其添加到 PATH。","categories":[],"tags":[]},{"title":"安装docker machine","slug":"安装docker-machine","date":"2024-01-12T07:16:29.000Z","updated":"2024-01-12T07:16:45.755Z","comments":true,"path":"2024/01/12/安装docker-machine/","permalink":"http://example.com/2024/01/12/%E5%AE%89%E8%A3%85docker-machine/","excerpt":"","text":"安装Docker Machine Docker Machine 是一个工具，用于在各种平台上安装和管理 Docker。以下是在不同操作系统上安装 Docker Machine 的方法： 对于 macOS 和 Windows： 对于 macOS 和 Windows 用户，建议安装 Docker Desktop，它包含 Docker Machine。访问 Docker 官网，根据您的操作系统选择合适的版本进行下载和安装。 对于 Linux： 下载最新版本的 Docker Machine 二进制文件： 123base=https://github.com/docker/machine/releases/download/v0.16.2 &amp;&amp;curl -L $base/docker-machine-$(uname -s)-$(uname -m) &gt;/tmp/docker-machine &amp;&amp;sudo install /tmp/docker-machine /usr/local/bin/docker-machine 上述命令将下载 v0.16.2 版本的 Docker Machine。您可以访问 Docker Machine 发布页面 查看最新版本并相应地更新上述命令。 添加可执行权限： 1sudo chmod +x /usr/local/bin/docker-machine 验证安装： 1docker-machine version 如果安装成功，您将看到 Docker Machine 的版本信息。 安装 Bash Completion（可选）： 为了获得更好的命令行体验，您可以安装 Docker Machine 的 Bash Completion。以下是在不同操作系统上安装的方法： 对于 macOS，您可以使用 Homebrew 安装： 12brew install bash-completion 对于 Linux（Debian&#x2F;Ubuntu）： 1sudo apt-get install bash-completion 对于其他 Linux 发行版，请查阅相应文档以获取正确的安装命令。 然后，将以下内容添加到您的 ~/.bashrc、~/.bash_profile 或 ~/.profile 文件中： 123if [ -f $(brew --prefix)/etc/bash_completion ]; then . $(brew --prefix)/etc/bash_completionfi 重新启动终端以使更改生效。 现在，您应该已经成功安装了 Docker Machine。您可以通过运行 docker-machine 命令查看可用选项和子命令。要了解如何使用 Docker Machine，请参阅 Docker Machine 官方文档。","categories":[],"tags":[]},{"title":"安装卸载mysql","slug":"安装卸载mysql","date":"2024-01-12T07:14:19.000Z","updated":"2024-01-13T13:06:04.095Z","comments":true,"path":"2024/01/12/安装卸载mysql/","permalink":"http://example.com/2024/01/12/%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BDmysql/","excerpt":"","text":"一，Linux的YUM在线的MySQL5.7安装😘 工欲善其事必先利其器，要学习Mysql的知识，首先先必须安装Mysql，本教程提供两种Mysql的安装方法 问题描述一般通过yum的在线安装，但是如果更换源以后会出现mysql-server按装包找不到的情况，这时候可以考虑用rpm包来安装，最后再执行yum install mysql-server rpm包的安装方式：mysql_免费高速下载|百度网盘-分享无限制 (baidu.com) ,具体如何放文件，自己决定，可以通过SFTP来传输。 φ(*￣0￣)安装数据库 1.传输完成后： yum -y install 你下的包.rpm 这样做的原因是阿里官网的yum库没有此软件包，所以你必须自己安装依赖。 2.如果执行成功后： yum -y install mysql-server 3.启动mysql服务： systemctl start mysqld 或者 service mysqld start 4.设置mysql服务自启动 systemctl enable mysqld 5.查看数据库密码 cat /var/log/mysqld.log | grep password , 或着你不想查看也可以，可以在 &#x2F;etc&#x2F;my.cnf 中编辑 ，加入一句话叫 skip-grant-tables 这句话的意思是说，可以不用输入密码进入mysql服务器中。 mysql -uroot -p q(≧▽≦q)当进入数据库中 首先先执行一编 flush privileges; 然后再进入修改密码：set password for 'root'@'localhost'=password('你的密码');，如果提示密码不符合规定的话。（ps 如果是新版的mysql的话直接输入set password=\"xxxx\"就行 就执行 set global validate_password_policy=0; #将密码强度设置为最低 然后 flush privileges;最后再执行一下你的set密码的语句，然后再flush privileges; 最后exit，再进入mysql试试。 （￣︶￣）↗ Mysql的远程连接 当一切准备就绪后，如果成功进入mysql了,看到mysql&gt;的话，那么就试试远程连接 首先先 ：use mysql; 第二步 ：update user set host='%' where user ='root'; 最后 ： flush privileges; 最后，最后，最后 ！！！！！ 如果连接不成功的话，那么请关闭防火墙，systemctl stop firewalld.service或者 firewall-cmd --zone=public --add-port=3306/tcp --permanent如果您使用阿里云的云服务器，因为作者是使用本机的linux服务器的，所以多一个步骤就是将在阿里云开启3306端口。 二，Linux的离线的MySQL5.7安装😘 ( •̀ ω •́ )✧首先先自己下载 https://dev.mysql.com/downloads/mysql/ Mysql的离线包，选择第二个64位的 Linux-Generic 下载了包以后用SFTP软件传到你想安装的目录下 第一步：先看看Linux服务器中有没有 Mariadb，有的话先卸载，卸载没遇到过，可以去百度，以为作者的服务器的啥样不是 第二步：删除&#x2F;etc&#x2F;my.cnf文件，因为会影响配置，所以先卸载了再说，后面可以再加上去 第三步：创建mysql用户组: groupadd mysql 第四步：加入到mysql用户组里面 useradd -g mysql mysql 注意！！作者之前操作问题，好像有mysql用户组，如果有的话，先执行一下，提升有的话，可以跳过第三部和第四步 进入你创建的目录下，比如 mkdir /data，将你的压缩包放在data下面，然后执行解压操作：tar -zxvf xxxxx.tar.gz 解压以后将解压的文件进行重命名操作 mv xxxx mysql 然后新建一个vi /etc/my.cnf，并且在里面写 [mysql]default-character-set&#x3D;utf8socket&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock[mysqld]skip-name-resolveport&#x3D;3306socket&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sockbasedir&#x3D;&#x2F;data&#x2F;mysql #主要这里是mysql安装路径datadir&#x3D;&#x2F;data&#x2F;mysql&#x2F;data #这里主要是mysql存储路径，以你创建的为例max_connections&#x3D;200character-set-server&#x3D;utf8default-storage-engine&#x3D;INNODBlower_case_table_names&#x3D;1max_allowed_packet&#x3D;16M :x保存退出 第五步：设置mysql用户： mkdir /var/lib/mysql mkdir /var/lib/mysql/mysql chown -R mysql:mysql /var/lib/mysql chown -R mysql:mysql /var/lib/mysql/mysql 第六步： 进入安装mysql软件目录 cd /data/mysql chown -R mysql:mysql ./ cd bin ./mysqld --user=mysql --basedir=/data/mysql --datadir=/data/mysql/data/ --initialize cd /data/mysql chown -R mysql:mysql data #修改当前data目录拥有者为mysql用户 第七步： 修改权限： chmod +x /etc/my.cnf 复制启动脚本到资源目录cd /home/mysql/ cp ./support-files/mysql.server /etc/init.d/mysqld 加入权限: chmod +x /etc/init.d/mysqld 将mysqld服务加入到系统服务chkconfig --add mysqld 检查mysqld服务是否已经生效chkconfig --list mysqld，如果出现mysqld 0:off 1:off 2:on 3:on 4:on 5:on 6 说明成功 将mysql的bin目录加入PATH环境变量，编辑&#x2F;etc&#x2F;profile文件vi /etc/profile export PATH=$PATH:/data/mysql/bin source /etc/profile #最后执行生效 🐎到最后mysql离线版本算是安装完成了，后面远程连接，修改密码操作参考第一个yum在线安教程的连接方法。 三，Linux完全卸载MySQL5.7😘 如果要完完全全删除mysql，不能用yum remove 操作，因为删不干净，还会有残留包，因为作者是离线安装所以没有图片展示 首先：先查看mysql的组件包: rpm -qa | grep -i mysql 第二步：关闭mysql服务： service mysqld stop 或者 systemctl stop mysqld 第三步：查看mysql对应文件夹: find / -name mysql 第四步：删除组件：rpm -ev –nodeps xxxx组件包名 第五步：删除mysql所以有配置文件夹： rm -rf /var/lib/mysql,不止这么多，第三步列出来的有什么就删除什么 最后：执行第一步和第三步如何啥也没有就说明彻底卸载了","categories":[],"tags":[]},{"title":"caddy 出现的问题","slug":"caddy","date":"2024-01-11T14:01:53.000Z","updated":"2024-01-12T01:49:03.592Z","comments":true,"path":"2024/01/11/caddy/","permalink":"http://example.com/2024/01/11/caddy/","excerpt":"","text":"Caddy解决404问题 这个问题可能是由于Caddy默认不支持单页应用（SPA）的路由机制导致的。当您刷新浏览器时，请求会直接发送到Caddy服务器，由于Caddy不知道如何处理这个特定的路由，因此返回404错误。要解决这个问题，您需要配置Caddyfile来处理单页应用的路由。以下是一个Caddyfile的示例配置，它为您的单页应用提供了一个通用的回退机制。它将确保所有未知的请求都会回退到您的index.html文件，这将允许前端路由器正确处理请求： 12345your_domain.comroot * /path/to/your/projectfile_servertry_files &#123;path&#125; /index.html 在这个示例中，请替换your_domain.com为您的实际域名，将&#x2F;path&#x2F;to&#x2F;your&#x2F;project替换为您的项目文件夹的路径。这个配置文件定义了一个try_files指令，它会尝试按照顺序提供列表中的文件。如果当前请求的路径在文件系统中不存在，它会回退到&#x2F;index.html文件。这将确保当您刷新浏览器时，前端路由器可以接管并正确处理请求。保存更改后，重新启动Caddy服务以应用新的配置。现在，您的单页应用应该可以在刷新浏览器后正常工作。 在Caddyfile中，{path}是一个占位符，表示当前请求的路径。当使用try_files指令时，它会尝试按照列表中的顺序提供文件。在这个例子中: 1try_files &#123;path&#125; /index.html {path}表示当前请求的实际路径。try_files首先尝试使用这个路径来查找文件。如果找到了匹配的文件，Caddy会将该文件提供给客户端。如果没有找到匹配的文件，try_files将按照列表中的顺序尝试下一个选项，这里是&#x2F;index.html。所以{path}确保Caddy首先尝试提供当前请求的实际路径。如果找不到对应的文件，它将回退到&#x2F;index.html。这在处理单页应用（SPA）中的前端路由时非常有用，因为这样可以确保当请求的路径在文件系统中不存在时，前端路由器仍然可以接管并正确处理请求。 如果这个以上方法不成功的话，可以使用以下配置： 你的问题可能与Caddy配置文件的处理顺序有关。请尝试以下Caddyfile配置： 12345678your_domain.comroot * /path/to/your/projectfile_serverrewrite * &#123;path&#125; /index.htmlroute &#123; try_files &#123;path&#125; /index.html&#125; 这个配置文件首先尝试使用rewrite指令重写所有请求。然后，它使用route块来定义一个处理请求的流程。try_files指令被包含在route块内，它首先尝试提供当前请求的实际路径（{path}），如果找不到匹配的文件，则会回退到&#x2F;index.html。请将your_domain.com替换为您的实际域名，将&#x2F;path&#x2F;to&#x2F;your&#x2F;project替换为您的项目文件夹的路径。更新Caddyfile后，重新启动Caddy服务以应用新的配置。刷新浏览器后，您的单页应用应该可以正常工作了。如果问题仍然存在，请检查Caddy的日志以获取有关错误的更多详细信息，并确保您的项目文件夹和index.html文件的路径正确。 Caddy日志 Caddy的日志位置取决于您的操作系统和Caddy的安装方式。以下是几种可能的日志位置：如果您是通过命令行手动运行Caddy（例如：caddy run），则日志将直接输出到命令行终端。如果您是使用Systemd管理的Caddy服务，可以使用以下命令查看日志：sudo journalctl -u caddy --since today这将显示今天的Caddy服务日志。您可以通过调整–since参数来查看更早的日志。如果Caddy已配置为将日志写入文件，那么您需要查找Caddyfile中指定的日志文件路径。例如，Caddyfile中可能包含如下配置： 123log &#123; output file /var/log/caddy/caddy.log&#125; 在这种情况下，您可以在&#x2F;var&#x2F;log&#x2F;caddy&#x2F;caddy.log找到日志。如果您不确定如何配置Caddy以将日志输出到文件，请参考以下Caddyfile示例： 12345678910your_domain.comroot * /path/to/your/projectfile_servertry_files &#123;path&#125; /index.htmllog &#123; output file /path/to/your/log/caddy.log format console&#125; 将&#x2F;path&#x2F;to&#x2F;your&#x2F;log替换为您希望存储日志文件的目录。这将使Caddy将其日志输出到指定的文件中。不同的操作系统和安装方式可能会影响Caddy日志的位置。如果您无法在上述位置找到日志，请查看Caddy文档或您操作系统的文档以获取更多详细信息。","categories":[],"tags":[]}],"categories":[],"tags":[]}